{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ecf8d54-7f78-425b-be1c-55ffad27b364",
   "metadata": {},
   "source": [
    "# QUESTION ANSWERING PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccc986ef-b174-4435-a2f7-e16ae74e88a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\rsdar\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\rsdar\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\rsdar\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\rsdar\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rsdar\\anaconda3\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\rsdar\\anaconda3\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\rsdar\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\rsdar\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rsdar\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffde548-3213-4697-a023-fc93650d5f43",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66526b8b-90ec-4f34-bc2a-1437d9c58547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "81c38871-b0f1-49bc-ba4a-582e9d72f5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "QA_input = [{'question': 'Why is conversion important?',\n",
    "             'context': 'The option to convert models between FARM and transformers gives freedom to the user and let people easily switch between frameworks'},\n",
    "            {'question': 'How many programming languages does BLOOM support?',\n",
    "             'context': \"BLOOM has 176 billion parameters and can generate text in 46 natural languages and 13 programming languages.\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb4cc232-4a90-4df6-817a-554d33b923c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting pretrained model from Hugging face \n",
    "model_name = \"deepset/roberta-base-squad2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f405ca31-6023-453a-be56-39943551e12f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a5f20ae0df24301896f2c9e9e296796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rsdar\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\rsdar\\.cache\\huggingface\\hub\\models--deepset--roberta-base-squad2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53f2d420d5d7460aba72d65ae2b4a2f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/496M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2226ad7beeb410bacd91eff008cb11d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/79.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a7ada83ef534f34b992f38e35e0c8e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4627a0c85fd94358a8fb8cddc016c0db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88b1e735c4914ef98027d6f94b21a08d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "18be5fb6-48e5-4c13-81e7-a334e9bbf080",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs0 = tokenizer(QA_input[0]['question'], QA_input[0]['context'], return_tensors='pt')\n",
    "output0 = model(**inputs0)\n",
    "inputs1 = tokenizer(QA_input[1]['question'], QA_input[1]['context'], return_tensors='pt')\n",
    "output1 = model(**inputs1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "398b537e-19e1-4776-99a5-3a677b57ef40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuestionAnsweringModelOutput(loss=None, start_logits=tensor([[ 1.7938, -7.3987, -8.5468, -8.3958, -8.4471, -9.2335, -3.2557, -7.5881,\n",
       "          0.5640, -0.9728, -3.3655, -2.9740, -3.9423, -5.2520, -5.5440, -7.5136,\n",
       "         -8.0409, -5.0296, -7.2065,  2.4705,  2.2460, -4.8768, -3.4340, -3.0591,\n",
       "         -3.9052,  0.5868, -5.0425, -2.6888, -2.7641, -5.8760, -4.1856, -3.2554]],\n",
       "       grad_fn=<CloneBackward0>), end_logits=tensor([[ 2.3119, -7.9505, -8.5171, -8.2700, -7.7651, -7.1173,  1.7775, -4.8996,\n",
       "         -6.5197, -4.9795, -7.5691, -7.0044, -4.7123, -7.8840, -7.8754, -4.3151,\n",
       "         -8.0943, -6.5522, -2.3138, -4.1120,  0.5433, -3.8706, -4.5866,  2.9418,\n",
       "         -3.3071, -5.3513, -4.6488, -2.9772, -3.5943, -3.1675,  2.4754,  1.7774]],\n",
       "       grad_fn=<CloneBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "accc3ddf-6a83-4c2c-a9cb-c60961a2446d",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_start_idx = torch.argmax(output0.start_logits)\n",
    "answer_end_idx = torch.argmax(output0.end_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "deadeb48-d00e-48e2-9894-6e9864756bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ques: Why is conversion important?\n",
      "answer:  gives freedom to the user\n"
     ]
    }
   ],
   "source": [
    "answer_tokens = inputs0.input_ids[0, answer_start_idx: answer_end_idx +1]\n",
    "answer = tokenizer.decode(answer_tokens)\n",
    "print(\"ques: {}\\nanswer: {}\".format(QA_input[0]['question'], answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "035f59a6-93a4-41a9-b33a-3bb1a419146a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ques: How many programming languages does BLOOM support?\n",
      "answer:  parameters and can generate text\n"
     ]
    }
   ],
   "source": [
    "answer_tokens = inputs1.input_ids[0, answer_start_idx: answer_end_idx + 1]\n",
    "answer = tokenizer.decode(answer_tokens)\n",
    "print(\"ques: {}\\nanswer: {}\".format(QA_input[1]['question'], answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dd182228-7213-4e54-a131-31b7dc7c3797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ques: How many programming languages does BLOOM support?\n",
      "answer:  parameters and can generate text\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# After decoding the predicted span:\n",
    "answer = tokenizer.decode(answer_tokens, skip_special_tokens=True)\n",
    "\n",
    "# Extract number if applicable\n",
    "number_match = re.search(r'\\d+', answer)\n",
    "if number_match:\n",
    "    answer = number_match.group()\n",
    "print(\"ques: {}\\nanswer: {}\".format(QA_input[1]['question'], answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bf330d0a-9741-4e22-a508-14271da1a908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ques: How many programming languages does BLOOM support?\n",
      "answer:  parameters and can generate text\n"
     ]
    }
   ],
   "source": [
    "print(\"ques: {}\\nanswer: {}\".format(QA_input[1]['question'], answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "78f61130-0119-4956-a400-785e6d580e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Method 2\n",
    "qa = pipeline('question-answering', model=model_name, tokenizer=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "50af0aeb-3c8f-4e4d-a723-85f44a4fc0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.16489499807357788, 'start': 59, 'end': 84, 'answer': 'gives freedom to the user'}\n"
     ]
    }
   ],
   "source": [
    "output_0 = qa(QA_input[0]['question'], QA_input[0]['context'])\n",
    "print(output_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "beb5f1af-2201-447c-8fbf-f81ccfb6452d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.9773292541503906, 'start': 83, 'end': 85, 'answer': '13'}\n"
     ]
    }
   ],
   "source": [
    "output_1 = qa(QA_input[1]['question'], QA_input[1]['context'])\n",
    "print(output_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be23a55-5b81-4bbc-84d9-bd6f747a75c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
